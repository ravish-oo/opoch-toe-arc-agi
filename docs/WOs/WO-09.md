**WO-09 — VALUE laws** that keeps “debugging = algebra” front and center, so implementers can self-catch bugs with concrete counterexamples, and reviewers can double-check deterministically after.

---

# WO-09 — VALUE laws (CONST, reducers, RECOLOR π, BLOCK(k))

## Purpose

Admit **VALUE** laws per truth-class by **proof**, not search. Each candidate law produces a **single color** for the class (possibly via a deterministic function of the training **input** class), and is **admitted** iff it reproduces **every training output** on **all observed pixels** of that class. Any disagreement or undefined read yields a **first counterexample** in receipts, so debugging reduces to one coordinate identity.

VALUE candidates here:

* `CONST(c)`
* Reducers on the **training input** class: `UNIQUE`, `ARGMAX`, `LOWEST_UNUSED`
* `RECOLOR(π)` per-class color permutation
* `BLOCK(k)` expansion motif (class-relative blow-up)

## Files

* `src/laws/value.py`  (new)
* uses: `src/receipts.py`, `src/morphisms.py` (WO-01), `src/truth.py` Partition (WO-06), `src/shape_law.py` pullback for **test painting later** (not used in training proof)

> **Note:** Proofs never use shape law; they operate on **training pairs** by conjugation of coordinates only.

---

## Inputs

* `part: Partition` — truth partition (Q) on **presented test input** (WO-06)
* Frames: `P_test`, `P_in[i]`, `P_out[i]` (WO-02)
* Presented grids: `Xin[i]` (train inputs: posed+anchored), `Yout[i]` (train outputs: posed-only), `Xtest` (test input: posed+anchored)
* For each class `cid`: its **test-frame** pixels `class_pixels_test` (list of coords from `part`)

---

## Deterministic helpers (frozen)

### H1) TEST→OUT witness set (what pixels must match)

For training pair `i`, a class `cid` is **observed** at the set:

```
Obs_i(cid) = { p_out in Yout[i] | q_test = pose_inv(p_out, P_out[i]);
               q_test ∈ class_pixels_test }
```

We will compare law output at `p_out` to `Yout[i][p_out]`. If `Obs_i(cid)` is empty for a train, it provides **no evidence** for that train.

### H2) TEST→IN class mask (for reducers & recolor)

For training pair `i`, map the class from **test frame** to **input frame**:

```
class_in_i = { p_in |
    q0 = pose_inv(p_test, P_test.op);
    q1 = anchor_inv(q0, P_test.anchor);
    q2 = anchor_fwd(q1, P_in[i].anchor);
    p_in = pose_fwd(q2, P_in[i].op);
    for some p_test ∈ class_pixels_test }
```

This is purely frame conjugation (no outputs, no shape). Use **set** semantics; dedup.

> You may implement this mapping as a small internal function (`test_to_in_class`) in this module to keep WO-01 stable.

---

## Candidate family definitions and admissibility

### 1) `CONST(c)`

* **Learn c:** For each train `i`, if `Obs_i(cid)` non-empty, collect colors `{ Yout[i][p_out] }`. They must be a **singleton**; denote it as `c_i`. All non-empty `c_i` across trains must be identical → `c`.
* **Proof:** For every train `i` and every `p_out ∈ Obs_i(cid)`, require `Yout[i][p_out] == c`.
* **Reject** if any train’s observed colors are not singleton or `c_i` disagree.

**Receipt witness on reject:** first `{train_idx, p_out, colors_seen}`.

### 2) Reducers on **training input** class

Compute a **candidate c_i** from `Xin[i]` restricted to `class_in_i` (H2). Every non-empty `class_in_i` must yield the **same** `c` across trains and the outputs must equal `c` on all observed pixels.

* `UNIQUE`: the set of input colors on `class_in_i` has size 1 → that color. Else **reject**.
* `ARGMAX`: color with maximum **count** on `class_in_i`; tie-break by **smallest color value**.
* `LOWEST_UNUSED`: smallest color in `0..9` **absent** from `class_in_i`. All trains with non-empty `class_in_i` must produce the same `c`.

**Proof:** For each train with `Obs_i(cid)`, require `Yout[i][p_out] == c` for all `p_out ∈ Obs_i(cid)`.

**Receipt witness on reject:** include `{train_idx, p_out, c_input: c_i, yout}` for the first mismatch; for `UNIQUE`, include a short frequency map snapshot.

### 3) `RECOLOR(π)` per class

* **Learn π:** For each train `i` and each `p_out ∈ Obs_i(cid)`, compute `p_in` by TEST→IN class mapping of its **source test pixel**:

  ```
  p_test = pose_inv(p_out, P_out[i].op)           # OUT → TEST
  # p_test ∈ class_pixels_test by construction
  p_in   = test_to_in(p_test, P_test, P_in[i])     # TEST → IN (frames only)
  cin    = Xin[i][p_in]
  cout   = Yout[i][p_out]
  add pair (cin → cout)
  ```

  Merge all pairs across trains. **Reject** if a color maps to two different outputs. Let the merged map be `π`.
* **Coverage requirement:** `π` must be **defined** for every input color that appears in the class on the **test input** (`Xtest` restricted to `class_pixels_test`).
* **Proof:** For each train and each `p_out ∈ Obs_i(cid)`, require `π[cin] == Yout[i][p_out]`.

**Receipt witness on reject:** if conflict, `{color: cin, seen: [cout1, cout2], train_idx, p_out}`; if missing coverage, `{missing_input_color: c, where:"test_class"}`.

### 4) `BLOCK(k)` (expansion motif; class-relative)

* **Intent:** Output color at an output pixel is the color of the **nearest** input class pixel under block factor `k` when measuring relative to a **class anchor**; this is a simple content-driven expansion without copying specific coordinates like KEEP.
* **Anchor of class:** `anchor = min(class_pixels_test)` in row-major (min row, then min col).
* **Definition:** For train `i` and `p_out ∈ Obs_i(cid)`, let:

  ```
  q_test = pose_inv(p_out, P_out[i].op)
  rel    = q_test - anchor                  # vector in TEST frame (row, col)
  base   = ( rel.row // k, rel.col // k )   # floor block index
  q0     = anchor + base                    # class cell representative in TEST
  p_in   = test_to_in(q0, P_test, P_in[i])  # TEST → IN frames only
  c_i    = Xin[i][p_in]
  ```

  Candidate law says OUTPUT must equal `c_i` at this `p_out`.
* **Admissibility:** All observed `p_out` across all trains must satisfy the equality. `k` is enumerated deterministically from a small set, e.g., divisors of `Ht,Wt` in ascending order, capped to `{2,3,4}` unless receipts later require more (see sieve in WO-10).
* **Reject** on first mismatch.

**Receipt witness on reject:** `{k, train_idx, p_out, q_test, base, p_in, xin, yout}`.

> Note: This covers blow-up-style VALUE painting where KEEP(block_inverse(k)) would be the “copy” analogue. We keep both vocabularies; sieve will pick the exact one.

---

## API (exact)

```python
from typing import List, Tuple, Dict, Any

def admit_value_for_class(
    cid: int,
    class_pixels_test: List[Tuple[int,int]],      # TEST-frame pixels for this class
    Xin: List[List[List[int]]],                   # posed+anchored inputs
    Yout: List[List[List[int]]],                  # posed-only outputs
    Xtest: List[List[int]],                       # test input posed+anchored
    P_test, P_in_list, P_out_list
) -> Dict[str, Any]:
    """
    Returns {"cid": cid, "admitted": [ ...value descriptors... ],
             "debug": [ ...first-witness records for rejects... ]}

    Each admitted descriptor is a canonical string, e.g.:
      "CONST(c=4)", "UNIQUE", "ARGMAX", "LOWEST_UNUSED",
      "RECOLOR(pi={2:6, 3:1})", "BLOCK(k=3)"
    """
```

All VALUE proofs are **total** over observed pixels: any undefined read is a logic bug; raise with a witness (should not happen in VALUE).

---

## Receipts (extend `"laws"`; same section as KEEP)

Add to the existing `laws` receipt for this task:

* Append to `"admitted"` entries of the form:

```json
{ "class_id": 7, "descriptor": "RECOLOR(pi={2:6,3:1})",
  "proof": { "trains_checked": 3, "pixels_checked": 128 } }
```

* When `ARC_SELF_CHECK=1`, also include `"value_debug"` list for first rejections with structured witnesses as described above.

One `receipts.log("laws", ...)` per task update; merge KEEP + VALUE in one payload or call twice and merge (module decides). Determinism requires stable ordering by `cid` then descriptor string.

---

## Built-in self-check (debugging = algebra)

Guarded by `ARC_SELF_CHECK=1`, run `_self_check_value()` once after admitting a couple of classes on synthetic fixtures:

1. **CONST**
   Two trains whose outputs write a solid color on the observed class; ensure `CONST(c)` admits and `c` matches both trains. Negative: make one pixel different; ensure first witness points to that pixel.

2. **UNIQUE/ARGMAX/LOWEST_UNUSED**
   Build input class masks where:

   * UNIQUE holds in both trains → admit UNIQUE (and CONST if outputs match).
   * ARGMAX differs without tie → admit ARGMAX with deterministic tie rule.
   * LOWEST_UNUSED consistent across trains → admit; negative: change train2 mask to produce different `c`, reject with witness.

3. **RECOLOR(π)**
   Two trains that realize a consistent color permutation on the class. Ensure π merges without conflicts and is defined for all test-class input colors. Negative: introduce a conflict cin→{x,y}; rejection witness must show both couts and the pixel.

4. **BLOCK(k)**
   Craft a blow-up example with k=2 that matches outputs; admit BLOCK(k=2). Negative: mismatch one cell; witness shows `base` and `p_in`.

Fail with `AssertionError("value self-check failed: <case>")` and include the first witness object’s summary.

---

## Acceptance (implementer)

* Deterministic admitted list per class; descriptors canonicalized; **no TODOs.**
* For each admitted law, `"pixels_checked"` equals `Σ_i |Obs_i(cid)|`.
* With `ARC_SELF_CHECK=1`, self-check passes; `"value_debug"` contains exactly one first witness per rejected candidate kind, not noisy logs.
* Implementer pastes the `"laws"` receipt snippet (admitted + value_debug) for one real class.

---

## Reviewer (after implementation)

Write tests that:

* Confirm CONST accepts only when all trains’ observed outputs are singleton and equal.
* Confirm reducers compute on **training input** class masks (not outputs), and deterministic tie rules are enforced.
* Confirm RECOLOR(π) learns per class, rejects on conflict, and covers all test-class input colors.
* Confirm BLOCK(k) works on a crafted blow-up and rejects with algebraic witness when wrong.
* Confirm determinism: descriptor order stable; witnesses stable for fixed seeds.

No malformed inputs; ARC is controlled.

---

## Prohibited

* Sampling observed pixels.
* Using outputs to define reducers (reducers depend on **Xin[class]**, not Yout).
* Quietly accepting RECOLOR with partial π (missing a test-class color).
* Any non-deterministic enumeration or tie rule.

---

## How implementers use receipts to debug (explicit)

1. Run with `ARC_SELF_CHECK=1`.
2. If a candidate fails, take the **first witness** in `"value_debug"`: it is a single pixel with exact coordinates and expected vs actual color.
3. Recompute the mapping by hand:

   * For RECOLOR: `p_out → pose_inv → p_test → test_to_in → p_in → Xin[p_in]` and check π.
   * For reducers: recompute `c_i` from `Xin[class_in_i]`; confirm conflict.
   * For BLOCK: recompute `base = floor((p_test - anchor)/k)` and the implied `p_in`.
4. Fix the algebra or reject the descriptor. **Do not skip tests.** One counterexample is sufficient to make progress.

---

This WO completes the VALUE side of your law vocabulary with receipts-tight proofs. Combined with KEEP (WO-08), the sieve (WO-10) will now be able to prune locally plausible but globally false laws and pick the least admissible exact one—pure algebra, no vibes.

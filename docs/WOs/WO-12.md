Tight, zero-wiggle **WO-12 — Hard-set run + descriptor closure + submission driver** that keeps “debugging = algebra” to the very end and gets you Kaggle-ready.

---

# WO-12 — Hard-set run + descriptor closure + submission driver

## Purpose

1. Run the **entire training corpus** end-to-end with Π → Q → Shape → KEEP/VALUE proofs → Sieve → Paint, collecting receipts per task.
2. When any task returns `missing_descriptor`, produce a **constructive certificate** (first witnesses) and perform **one minimal, additive vocabulary extension**; re-run deterministically until **no missing_descriptor remains**.
3. Build the **submission driver** that paints test outputs and writes `submission.json` (Kaggle format), receipts-tight and deterministic.

## Files

* `src/runner.py` — batch runner for the full corpus (train + test).
* `src/descriptor_registry.py` — single source of truth for the law catalogue and cost order; additive-only updates.
* `src/report.py` — aggregates receipts across tasks; prints closure progress.
* `main.py` — Kaggle entrypoint (reads `test/` tasks, writes `submission.json`).
* touches: existing modules only via their public APIs.

> No new deps. No TODOs. Determinism preserved.

---

## Inputs

* The ARC training set (JSON tasks with train/test).
* Your pipeline modules from WO-01…11.
* Anchors in `docs/anchors/` (for prompts and reviewer).

---

## A) Descriptor registry (single place to extend, additive-only)

### `src/descriptor_registry.py`

Provide three surfaces:

```python
# KEEP catalogue (test-frame views), deterministic order
def keep_catalogue(Ht: int, Wt: int, sviews_meta: dict) -> List[KeepCandidate]:
    """
    Calls enumerate_keep_candidates(...) from laws/keep.py.
    Ht,Wt from presented test input; sviews_meta carries gcds etc.
    """

# VALUE catalogue (per-class), deterministic order
def value_catalogue() -> List[str]:
    """
    Returns canonical VALUE descriptor names you support:
    ["CONST", "UNIQUE", "ARGMAX", "LOWEST_UNUSED", "RECOLOR", "BLOCK"]
    """

# Cost order (canonical)
def cost_order() -> List[str]:
    return [
        "KEEP:tile_alt_*", "KEEP:tile", "KEEP:d4_*", "KEEP:identity",
        "RECOLOR", "BLOCK", "ARGMAX", "UNIQUE", "LOWEST_UNUSED", "CONST"
    ]
```

**Additive-only rule:** any new descriptor must be appended in a place that keeps total order consistent; never rename or remove.

---

## B) Batch runner (train-corpus algebra loop)

### `src/runner.py`

API:

```python
def run_training_corpus(tasks: List[TaskJson]) -> Dict:
    """
    For each task:
      1) Π present all grids; log "present"
      2) Build sviews (incl. residue-k); log "sviews"
      3) Build components; log "components"
      4) Build truth Q; log "truth"
      5) Learn shape law; log "shape"
      6) Admit KEEP per class via keep_catalogue; VALUE via value_catalogue; log "laws"
      7) Build class_map_i; run sieve; log "selection"
      8) If status=="exact": paint once; un-present; compare to official Ytrain; log "paint"
         else: skip paint and keep "missing_descriptor" with witnesses
    Returns a summary dict with per-task statuses and an overall report.
    """
```

Deterministic pass order: task ids ascending; within task, your fixed orders already apply.

---

## C) Descriptor-closure loop (mechanical, receipts-first)

### What the runner records per task

* `status`: `"exact"` or `"missing_descriptor"`.
* If exact: `train_match_ok` (every train pair byte-equal).
* If missing: `missing = [{"cid": <cid or "⊥">, "examples": [...w1,w2,w3]}]` pulled from `"selection"` receipts.

### `src/report.py`

* Aggregate counts: exact vs missing.
* Print **first witness** per missing class: `{task_id, cid, train_idx, p_out, expected, got, path}`.
* Compute a **stable hash** over the (task_id, cid, descriptor?) lines to certify determinism.

### Extension protocol (additive-only)

When any missing remains:

1. Inspect 1–3 witnesses (algebra only) and decide the **single minimal descriptor** to add:

   * KEEP: a specific view (e.g., `tile_alt_checker_flip` if you didn’t include it).
   * VALUE: a tiny variant (e.g., `LOWEST_UNUSED_EXCEPT{0,1}`) — only if truly demanded by witnesses and provable on inputs.
2. Add it in `descriptor_registry.py` (and the corresponding implementation file) with:

   * Deterministic enumeration rules,
   * Admissibility proof (WO-08/09 style),
   * Unit self-check in that module guarded by `ARC_SELF_CHECK=1`.
3. **Re-run** `run_training_corpus` and the report.
4. Repeat until **no missing**.

> This is finite: each addition must be receipts-justified by a published witness. No speculative bloat.

---

## D) Submission driver (Kaggle)

### `main.py`

* Reads test tasks from Kaggle input (`/kaggle/input/arc-prize-2024/` or provided path).
* For each task:

  1. Present (Π) inputs + test input; learn shape; build sviews + components; build truth Q; admit laws; sieve; **must return status="exact"** (you’re already closed on train set).
  2. Paint once on test canvas; un-present to raw.
* Write a `submission.json` mapping `{task_id: [test_output_grids...]}`.

No internet; no randomness; identical outputs across runs.

---

## Receipts (global run)

### Task-level: already logged by modules

* `"present"`, `"sviews"`, `"components"`, `"truth"`, `"shape"`, `"laws"`, `"selection"`, `"paint"`.

### Corpus-level: new `report` section

At the end of `run_training_corpus`, emit:

```json
{
  "report": {
    "tasks_total": N,
    "exact": K,
    "missing": N-K,
    "missing_examples": [
      {"task_id":"abcd1234","cid":"⊥","train_idx":1,"p_out":[2,7],
       "expected":5,"got":2,"path":{"p_test":null}}
    ],
    "hash": "sha256-of-canonical-report-json"
  }
}
```

Deterministic: keys sorted, lists in fixed order. Reviewer will check that the hash doesn’t change under train-pair permutation.

---

## Built-in self-check (debugging = algebra)

Guarded by `ARC_SELF_CHECK=1`, `runner.py` should run a **mini-corpus** (your microsuite 6 tasks + 1 synthetic with unseen pixels) and assert:

1. **Microsuite exact** — all six pass; `status="exact"`.
2. **Unseen pixels** — synthetic task produces `"⊥": "CONST(c)"` or a `missing_descriptor` with witness.
3. **Determinism** — re-run mini-corpus; same global `report.hash`.

On failure, print the **first witness** from `missing_examples` and raise `AssertionError("runner self-check failed: <case>")`.

---

## Acceptance (implementer)

* `descriptor_registry.py` exists and is the **only** place you add descriptors; cost order exported.
* `run_training_corpus` produces a corpus summary; receipts present per task; determinism holds.
* `report.py` prints closure progress and witnesses.
* `main.py` writes a valid `submission.json` using the same pipeline; deterministic outputs.
* With `ARC_SELF_CHECK=1`, self-check passes.

Paste:

* The corpus-level `report` JSON fragment,
* One example `selection` receipt that previously had `missing_descriptor` and is now exact,
* The first 3 lines of your generated `submission.json` (for any 1–2 tasks).

---

## Reviewer (after implementation)

* Run the full training corpus. Confirm:

  * No `missing_descriptor` remains, or if it does, the witnesses make *one* new descriptor obviously necessary.
  * Descriptor additions are **minimal** and **additive**.
  * Determinism: two full runs → identical report hash.
* Run `main.py` on a local subset of test tasks and validate format and idempotence.
* Ensure no module writes silent zeros; all failures surface as witnesses.

---

## Prohibited

* Changing anchors, tie-breakers, or cost order semantics retroactively.
* Removing or renaming descriptors (breaks determinism).
* Using outputs to define predicates or descriptors (they are used only for comparison).
* Skipping failing tests; **one witness** is sufficient to fix.

---

## How Claude should use receipts to debug (explicit)

* If `missing_descriptor` appears, open the first witness; reproduce one pixel path:

  * For KEEP: `p_out → pose_inv → V(p_test) → anchor_fwd → pose_fwd → p_in` then compare `Xin[p_in]` vs `Yout[p_out]`.
  * For RECOLOR: compute `cin` and `π[cin]` vs `Yout[p_out]`.
  * For BLOCK: recompute `base` from class anchor; derive `p_in`.
* Decide the **single smallest** descriptor that makes that pixel (and its class) provable. Add it in `descriptor_registry`, implement it with an admissibility proof, and re-run.

---

With WO-12, the whole thing is a deterministic compiler with a finite, receipts-first closure process. If anything remains, you’ll know exactly which single law to add and why; otherwise you’re Kaggle-ready with a one-pass painter and a reproducible `submission.json`.
